---
title: 'Maciej Cegłowski on the Danger of Data'
publishedAt: '2016-09-13'
summary: 'I wrote recently about thoughts that have been swirling in my head about data and privacy in the world we live in today[^1]. Being back in the swing of things full time at work, I've been reminded mor...'
categories: ['Nerdery']

---

I wrote recently about thoughts that have been swirling in my head about data and privacy in the world we live in today[^1]. Being back in the swing of things full time at work, I've been reminded more than ever that, in many ways, data is power.

I chose not to qualify the idea that data is power (by saying "in the modern economy," for example), because information has always provided power in some shape or form throughout history. Spying has been a job for a very long time. At the same time, I can't help but sense that the ease with which data is collected today (using modern technology) and the mind-blowing *amount* of data presents us with unique circumstances as far as the amount of leverage that data can provide its owners.

As I've thought and read about the future of data and its potential uses, I've often felt like seeking to be a realist has flirted with what sounds like conspiracy theory—far more than I'd like it to. Which is why I'm glad there are much smarter people thinking about similar things.

**Thinking from someone much smarter than me**

On a recent Instapaper binge, I ran across a talk I'd saved by a man named Maciej Cegłowski. The article details his remarks are from a panel on the Moral Economy of Tech at the SASE conference[^2]. The entire piece is excellent and worth digesting. Cegłowski handles the balance between realism and potential danger deftly. Here are a few quotes to whet your appetite: > Today we are embarked on a great project to make computers a part of everyday life. As Marc Andreessen memorably frames it, "software is eating the world". And those of us writing the software expect to be greeted as liberators.

Our intentions are simple and clear. First we will instrument, then we will analyze, then we will optimize. And you will thank us.

But the real world is a stubborn place. It is complex in ways that resist abstraction and modeling. It notices and reacts to our attempts to affect it. Nor can we hope to examine it objectively from the outside, any more than we can step out of our own skin.

The connected world we're building may resemble a computer system, but really it's just the regular old world from before, with a bunch of microphones and keyboards and flat screens sticking out of it. And it has the same old problems.

• • •

> In the real world, this has led to a pathology where the tech sector maximizes its own comfort. You don't have to go far to see this. Hop on BART after the conference and take a look at Oakland, or take a stroll through downtown San Francisco and try to persuade yourself you're in the heart of a boom that has lasted for forty years. You'll see a residential theme park for tech workers, surrounded by areas of poverty and misery that have seen no benefit and ample harm from our presence. We pretend that by maximizing our convenience and productivity, we're hastening the day when we finally make life better for all those other people.

• • •

> Surveillance capitalism has some of the features of a zero-sum game. The actual value of the data collected is not clear, but it is definitely an advantage to collect more than your rivals do. Because human beings develop an immune response to new forms of tracking and manipulation, the only way to stay successful is to keep finding novel ways to peer into people's private lives. And because much of the surveillance economy is funded by speculators, there is an incentive to try flashy things that will capture the speculators' imagination, and attract their money.

This creates a ratcheting effect where the behavior of ever more people is tracked ever more closely, and the collected information retained, in the hopes that further dollars can be squeezed out of it.

• • •

> We're used to talking about the private and public sector in the real economy, but in the surveillance economy this boundary doesn't exist. Much of the day-to-day work of surveillance is done by telecommunications firms, which have a close relationship with government. The techniques and software of surveillance are freely shared between practitioners on both sides. All of the major players in the surveillance economy cooperate with their own country's intelligence agencies, and are spied on (very effectively) by all the others.

• • •

> When we talk about the moral economy of tech, we must confront the fact that we have created a powerful tool of social control. Those who run the surveillance apparatus understand its capabilities in a way the average citizen does not. My greatest fear is seeing the full might of the surveillance apparatus unleashed against a despised minority, in a democratic country.

What we've done as technologists is leave a loaded gun lying around, in the hopes that no one will ever pick it up and use it.

• • •

> We should not listen to people who promise to make Mars safe for human habitation, until we have seen them make Oakland safe for human habitation. We should be skeptical of promises to revolutionize transportation from people who can't fix BART, or have never taken BART. And if Google offers to make us immortal, we should check first to make sure we'll have someplace to live.

[^1]: You can read my article called “Facebook, Photos, Privacy and Parenthood,” [here](https://ericdodds.com/facebook-photos-privacy-and-parenthood/).



[^2]: You can read Maciej Cegłowski's full talk, called "The Moral Economy of Tech," [on his website](http://idlewords.com/talks/sase_panel.htm).
